# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

###############################################################################
#
# singer log configuration for logs in thrift_logger format
#
###############################################################################

#[required] log name that is unique among the singer log configurations
logName=tutorial_thrift_log

#[required] directory of the log files
logDir=/tmp/singer_tutorial/data

#[required] regular expression for matching the log streams
logStreamRegex=thrift_log_sample.log

# [required] `logFileMatchMode` tells Singer how to match a log stream based on the log file
#            There are two match mode: `prefix` matching, and `exact` matching
#            Let a log stream be 'service.log,  service.log.1, service.log.2 ....',
#            and logStreamRegex be `service.log`, using `exact` match, Singer will only process the file `service.log`
#            Using `prefix` matching, Singer will process `service.log.*` files.
logFileMatchMode=prefix

###############################################################################
#
# Configuration for log stream processor.
#
###############################################################################
#[required] batch size for writing messages
processor.batchSize=400

# [required] log stream processor's processing interval in milliseconds if there is no new events
#            in the log stream, or the processing time exceeds the `ProcessingTimeSlice` limit
processor.processingIntervalInMilliseconds=200

#[required] maximum processing interval for backing off if no new messages come in
processor.processingIntervalInMillisecondsMax=200

#[required] processing slice in second. the current logstream processor thread will
#           yield to process other log streams after using up the time slice.
processor.processingTimeSliceInSeconds=15


###############################################################################
#
# Configuration for reading the log files in thrift_logger format
#
###############################################################################
#[required] reader.type is 'thrift'
reader.type=thrift

#[required] reader buffer size
reader.thrift.readerBufferSize=2097152

#[required] max message size.
reader.thrift.maxMessageSize=1000000


###############################################################################
#
# Configuration for writing data to kafka
#
###############################################################################
writer.type=kafka
writer.kafka.topic=singer_tutorial
writer.kafka.producerConfig.bootstrap.servers.file=/tmp/singer_tutorial/kafka_server.txt
writer.kafka.producerConfig.acks=1
writer.kafka.producerConfig.compression.codec=none
writer.kafka.producerConfig.max.request.size=2097152

#[optional] SSL related kafka producer setting
writer.kafka.producerConfig.ssl.enabled=false 
writer.kafka.producerConfig.ssl.client.auth=required
writer.kafka.producerConfig.ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1
writer.kafka.producerConfig.ssl.endpoint.identification.algorithm=HTTPS
writer.kafka.producerConfig.ssl.key.password=$key_password
writer.kafka.producerConfig.ssl.keystore.location=$keystore_location
writer.kafka.producerConfig.ssl.keystore.password=your_password
writer.kafka.producerConfig.ssl.keystore.type=JKS
writer.kafka.producerConfig.ssl.secure.random.implementation=SHA1PRNG
writer.kafka.producerConfig.ssl.truststore.location=$trust_store_location
writer.kafka.producerConfig.ssl.truststore.password=$truststore_password
writer.kafka.producerConfig.ssl.truststore.type=JKS

